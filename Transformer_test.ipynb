{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and fix up for transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m dataset_progressive_skill:\n\u001b[0;32m---> 11\u001b[0m     game_id, board, move, player1_skill, player2_skill, player \u001b[38;5;241m=\u001b[39m record\n\u001b[1;32m     12\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     13\u001b[0m         {\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGame ID\u001b[39m\u001b[38;5;124m\"\u001b[39m: game_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m         }\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     23\u001b[0m connect4 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 6)"
     ]
    }
   ],
   "source": [
    "# Replace 'your_file.pkl' with the path to your pickle file\n",
    "file_path = \"Connect4Dataset_RandomOpp_Firstmove.pkl\"\n",
    "\n",
    "# Open the pickle file in read mode\n",
    "with open(file_path, \"rb\") as file:\n",
    "    dataset_progressive_skill = pickle.load(file)\n",
    "\n",
    "# Convert the dataset to a DataFrame, including board state\n",
    "data = []\n",
    "for record in dataset_progressive_skill:\n",
    "    game_id, board, move, player1_skill, player2_skill, player = record\n",
    "    data.append(\n",
    "        {\n",
    "            \"Game ID\": game_id,\n",
    "            \"Board State\": board,\n",
    "            \"Move\": move,\n",
    "            \"Player 1 Skill\": player1_skill,\n",
    "            \"Player 2 Skill\": player2_skill,\n",
    "            \"Player\": player,\n",
    "        }\n",
    "    )\n",
    "\n",
    "connect4 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect4 = pd.read_pickle('Connect4Dataset_SmartRandom_combined.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_board_state(board, player):\n",
    "    \"\"\"\n",
    "    Swap [0,1] to [1,0] and [1,0] to [0,1] in a given board only if player == -1.\n",
    "    \"\"\"\n",
    "\n",
    "    # if isinstance(player, str):\n",
    "    #     player = int(player)\n",
    "\n",
    "    if player == \"minus\":\n",
    "        board = np.array(board)  # Ensure it's a NumPy array\n",
    "\n",
    "        # Create masks\n",
    "        mask_01 = (board[:, :, 0] == 0) & (board[:, :, 1] == 1)  # Find [0,1]\n",
    "        mask_10 = (board[:, :, 0] == 1) & (board[:, :, 1] == 0)  # Find [1,0]\n",
    "\n",
    "        # Swap values\n",
    "        board[mask_01] = [1, 0]\n",
    "        board[mask_10] = [0, 1]\n",
    "\n",
    "    return board  # Return the modified or original board\n",
    "\n",
    "\n",
    "# Apply to each board where the player is -1\n",
    "connect4_standardized = connect4.copy()\n",
    "connect4_standardized[\"Board State\"] = connect4_standardized.apply(\n",
    "    lambda row: standardize_board_state(row[\"Board State\"], row[\"Player\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1046484, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flip_board(board):\n",
    "    \"\"\"Flip the board horizontally.\"\"\"\n",
    "    return np.flip(board, axis=1)\n",
    "\n",
    "\n",
    "def add_flipped_boards(df):\n",
    "    \"\"\"\n",
    "    Add flipped boards to the dataset, updating the Game ID for flipped boards.\n",
    "    Args:\n",
    "        df: A Pandas DataFrame with columns \"Game ID\", \"Board State\", \"Move\",\n",
    "             \"Player 1 Skill\", \"Player 2 Skill\", and \"Player\".\n",
    "    Returns:\n",
    "        A new DataFrame with original and flipped boards, where flipped boards have updated Game IDs.\n",
    "    \"\"\"\n",
    "    flipped_rows = []\n",
    "    max_game_id = df[\n",
    "        \"Game ID\"\n",
    "    ].max()  # Start new Game IDs after the max ID in the original DataFrame\n",
    "\n",
    "    for game_id, group in df.groupby(\"Game ID\"):  # Group by each game\n",
    "        for _, row in group.iterrows():\n",
    "            # Extract board state, move, and other columns\n",
    "            board = row[\"Board State\"]\n",
    "            move = row[\"Move\"]\n",
    "            other_columns = row.drop(\n",
    "                [\"Game ID\", \"Board State\", \"Move\"]\n",
    "            ).to_dict()  # Extract other columns\n",
    "\n",
    "            # Add the original board state\n",
    "            flipped_rows.append(\n",
    "                {\n",
    "                    \"Game ID\": game_id,  # Keep the original Game ID\n",
    "                    \"Board State\": board,\n",
    "                    \"Move\": move,\n",
    "                    **other_columns,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Flip the board and adjust the move\n",
    "            flipped_board = flip_board(board)\n",
    "            flipped_move = 6 - move  # Adjust move for flipped board\n",
    "\n",
    "            # Add the flipped board state with a new Game ID\n",
    "            flipped_rows.append(\n",
    "                {\n",
    "                    \"Game ID\": max_game_id\n",
    "                    + 1,  # Increment Game ID for flipped board states\n",
    "                    \"Board State\": flipped_board,\n",
    "                    \"Move\": flipped_move,\n",
    "                    **other_columns,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Increment the max_game_id for the next game\n",
    "        max_game_id += 1\n",
    "\n",
    "    # Create a new DataFrame from the rows\n",
    "    return pd.DataFrame(flipped_rows)\n",
    "\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "connect4_wflip = add_flipped_boards(connect4_standardized)\n",
    "connect4_wflip.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer architecture Dans code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalIndex(tf.keras.layers.Layer):\n",
    "    def call(self, x):\n",
    "        bs = tf.shape(x)[0]  # extract batch size\n",
    "        number_of_vectors = tf.shape(x)[\n",
    "            1\n",
    "        ]  # how many vectors - we know it should be m*n, but let's count to be sure...\n",
    "        indices = tf.range(number_of_vectors)  # index for each vector\n",
    "        indices = tf.expand_dims(indices, 0)  # reshape it appropriately\n",
    "        return tf.tile(indices, [bs, 1])  # repeat for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassTokenIndex(tf.keras.layers.Layer):\n",
    "    def call(self, x):\n",
    "        bs = tf.shape(x)[0]  # extract batch size\n",
    "        number_of_vectors = 1  # how many vectors - we just want 1 (which is @ 0) ... we only want to generate 1 vector for the class token\n",
    "        # now just get it to be the right size\n",
    "        indices = tf.range(number_of_vectors)  # index for each vector\n",
    "        indices = tf.expand_dims(indices, 0)  # reshape it appropriately\n",
    "        return tf.tile(indices, [bs, 1])  # repeat for each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ViT(\n",
    "    size, \n",
    "    block_size,\n",
    "    hidden_dim,\n",
    "    num_layers,\n",
    "    num_heads,\n",
    "    key_dim,\n",
    "    value_dim,\n",
    "    mlp_dim,\n",
    "    dropout_rate,\n",
    "    num_classes,\n",
    "):\n",
    "    # n is number of rows of blocks\n",
    "    # m is number of cols of blocks\n",
    "    # block_size is number of pixels (with rgb) in each block\n",
    "    inp = tf.keras.layers.Input(shape=(size, block_size))\n",
    "    mid = tf.keras.layers.Dense(hidden_dim)(\n",
    "        inp\n",
    "    )  # transform to vectors with different dimension\n",
    "    # the positional embeddings\n",
    "    inp2 = PositionalIndex()(inp)\n",
    "    emb = tf.keras.layers.Embedding(input_dim=size, output_dim=hidden_dim)(\n",
    "        inp2\n",
    "    )  # learned positional embedding for each of the n*m possible possitions\n",
    "    mid = tf.keras.layers.Add()(\n",
    "        [mid, emb]\n",
    "    )  # for some reason, tf.keras.layers.Add causes an error, but + doesn't?\n",
    "    # create and append class token to beginning of all input vectors\n",
    "    tokenInd = ClassTokenIndex()(mid)\n",
    "    token = tf.keras.layers.Embedding(input_dim=1, output_dim=hidden_dim)(tokenInd)\n",
    "    mid = tf.keras.layers.Concatenate(axis=1)([token, mid])\n",
    "\n",
    "    for l in range(num_layers):  # how many Transformer Head layers are there?\n",
    "        ln = tf.keras.layers.LayerNormalization()(mid)  # normalize\n",
    "        mha = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=key_dim, value_dim=value_dim\n",
    "        )(\n",
    "            ln, ln, ln\n",
    "        )  # self attention!\n",
    "        add = tf.keras.layers.Add()([mid, mha])  # add and norm\n",
    "        ln = tf.keras.layers.LayerNormalization()(add)\n",
    "        den = tf.keras.layers.Dense(mlp_dim, activation=\"gelu\")(\n",
    "            ln\n",
    "        )  # maybe should be relu...who knows...\n",
    "        den = tf.keras.layers.Dropout(dropout_rate)(den)  # regularization\n",
    "        den = tf.keras.layers.Dense(hidden_dim)(\n",
    "            den\n",
    "        )  # back to the right dimensional space\n",
    "        den = tf.keras.layers.Dropout(dropout_rate)(den)\n",
    "        mid = tf.keras.layers.Add()([den, add])  # add and norm again\n",
    "\n",
    "    fl = mid[:, 0, :]  # just grab the class token for each image in batch\n",
    "    ln = tf.keras.layers.LayerNormalization()(fl)\n",
    "    clas = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(\n",
    "        ln\n",
    "    )  # probability that the image is in each category\n",
    "    mod = tf.keras.models.Model(inp, clas)\n",
    "    mod.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 69, 8)]      0           []                               \n",
      "                                                                                                  \n",
      " positional_index_1 (Positional  (None, 69)          0           ['input_2[0][0]']                \n",
      " Index)                                                                                           \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 69, 64)       576         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 69, 64)       4416        ['positional_index_1[0][0]']     \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 69, 64)       0           ['dense_26[0][0]',               \n",
      "                                                                  'embedding_2[0][0]']            \n",
      "                                                                                                  \n",
      " class_token_index_1 (ClassToke  (None, 1)           0           ['add_25[0][0]']                 \n",
      " nIndex)                                                                                          \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 1, 64)        64          ['class_token_index_1[0][0]']    \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 70, 64)       0           ['embedding_3[0][0]',            \n",
      "                                                                  'add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 70, 64)      128         ['concatenate_1[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, 70, 64)      24896       ['layer_normalization_25[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_25[0][0]', \n",
      "                                                                  'layer_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 70, 64)       0           ['concatenate_1[0][0]',          \n",
      "                                                                  'multi_head_attention_12[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 70, 64)      128         ['add_26[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 70, 64)       4160        ['layer_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 70, 64)       0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 70, 64)       4160        ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 70, 64)       0           ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 70, 64)       0           ['dropout_25[0][0]',             \n",
      "                                                                  'add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 70, 64)      128         ['add_27[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, 70, 64)      24896       ['layer_normalization_27[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_27[0][0]', \n",
      "                                                                  'layer_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 70, 64)       0           ['add_27[0][0]',                 \n",
      "                                                                  'multi_head_attention_13[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 70, 64)      128         ['add_28[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 70, 64)       4160        ['layer_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 70, 64)       0           ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 70, 64)       4160        ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 70, 64)       0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 70, 64)       0           ['dropout_27[0][0]',             \n",
      "                                                                  'add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 70, 64)      128         ['add_29[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, 70, 64)      24896       ['layer_normalization_29[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_29[0][0]', \n",
      "                                                                  'layer_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 70, 64)       0           ['add_29[0][0]',                 \n",
      "                                                                  'multi_head_attention_14[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 70, 64)      128         ['add_30[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 70, 64)       4160        ['layer_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 70, 64)       0           ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 70, 64)       4160        ['dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 70, 64)       0           ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 70, 64)       0           ['dropout_29[0][0]',             \n",
      "                                                                  'add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 70, 64)      128         ['add_31[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 70, 64)      24896       ['layer_normalization_31[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_31[0][0]', \n",
      "                                                                  'layer_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 70, 64)       0           ['add_31[0][0]',                 \n",
      "                                                                  'multi_head_attention_15[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 70, 64)      128         ['add_32[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 70, 64)       4160        ['layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 70, 64)       0           ['dense_33[0][0]']               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 70, 64)       4160        ['dropout_30[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)           (None, 70, 64)       0           ['dense_34[0][0]']               \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 70, 64)       0           ['dropout_31[0][0]',             \n",
      "                                                                  'add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 70, 64)      128         ['add_33[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, 70, 64)      24896       ['layer_normalization_33[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_33[0][0]', \n",
      "                                                                  'layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 70, 64)       0           ['add_33[0][0]',                 \n",
      "                                                                  'multi_head_attention_16[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_34 (LayerN  (None, 70, 64)      128         ['add_34[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 70, 64)       4160        ['layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, 70, 64)       0           ['dense_35[0][0]']               \n",
      "                                                                                                  \n",
      " dense_36 (Dense)               (None, 70, 64)       4160        ['dropout_32[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 70, 64)       0           ['dense_36[0][0]']               \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 70, 64)       0           ['dropout_33[0][0]',             \n",
      "                                                                  'add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_35 (LayerN  (None, 70, 64)      128         ['add_35[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, 70, 64)      24896       ['layer_normalization_35[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_35[0][0]', \n",
      "                                                                  'layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, 70, 64)       0           ['add_35[0][0]',                 \n",
      "                                                                  'multi_head_attention_17[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_36 (LayerN  (None, 70, 64)      128         ['add_36[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 70, 64)       4160        ['layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)           (None, 70, 64)       0           ['dense_37[0][0]']               \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 70, 64)       4160        ['dropout_34[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 70, 64)       0           ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, 70, 64)       0           ['dropout_35[0][0]',             \n",
      "                                                                  'add_36[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_37 (LayerN  (None, 70, 64)      128         ['add_37[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_18 (Multi  (None, 70, 64)      24896       ['layer_normalization_37[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_37[0][0]', \n",
      "                                                                  'layer_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, 70, 64)       0           ['add_37[0][0]',                 \n",
      "                                                                  'multi_head_attention_18[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_38 (LayerN  (None, 70, 64)      128         ['add_38[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 70, 64)       4160        ['layer_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 70, 64)       0           ['dense_39[0][0]']               \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 70, 64)       4160        ['dropout_36[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 70, 64)       0           ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, 70, 64)       0           ['dropout_37[0][0]',             \n",
      "                                                                  'add_38[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_39 (LayerN  (None, 70, 64)      128         ['add_39[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_19 (Multi  (None, 70, 64)      24896       ['layer_normalization_39[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_39[0][0]', \n",
      "                                                                  'layer_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 70, 64)       0           ['add_39[0][0]',                 \n",
      "                                                                  'multi_head_attention_19[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_40 (LayerN  (None, 70, 64)      128         ['add_40[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 70, 64)       4160        ['layer_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 70, 64)       0           ['dense_41[0][0]']               \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 70, 64)       4160        ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 70, 64)       0           ['dense_42[0][0]']               \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 70, 64)       0           ['dropout_39[0][0]',             \n",
      "                                                                  'add_40[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_41 (LayerN  (None, 70, 64)      128         ['add_41[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_20 (Multi  (None, 70, 64)      24896       ['layer_normalization_41[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_41[0][0]', \n",
      "                                                                  'layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 70, 64)       0           ['add_41[0][0]',                 \n",
      "                                                                  'multi_head_attention_20[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_42 (LayerN  (None, 70, 64)      128         ['add_42[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 70, 64)       4160        ['layer_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 70, 64)       0           ['dense_43[0][0]']               \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 70, 64)       4160        ['dropout_40[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 70, 64)       0           ['dense_44[0][0]']               \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 70, 64)       0           ['dropout_41[0][0]',             \n",
      "                                                                  'add_42[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_43 (LayerN  (None, 70, 64)      128         ['add_43[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_21 (Multi  (None, 70, 64)      24896       ['layer_normalization_43[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_43[0][0]', \n",
      "                                                                  'layer_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 70, 64)       0           ['add_43[0][0]',                 \n",
      "                                                                  'multi_head_attention_21[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_44 (LayerN  (None, 70, 64)      128         ['add_44[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 70, 64)       4160        ['layer_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 70, 64)       0           ['dense_45[0][0]']               \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 70, 64)       4160        ['dropout_42[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 70, 64)       0           ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 70, 64)       0           ['dropout_43[0][0]',             \n",
      "                                                                  'add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_45 (LayerN  (None, 70, 64)      128         ['add_45[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_22 (Multi  (None, 70, 64)      24896       ['layer_normalization_45[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_45[0][0]', \n",
      "                                                                  'layer_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 70, 64)       0           ['add_45[0][0]',                 \n",
      "                                                                  'multi_head_attention_22[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_46 (LayerN  (None, 70, 64)      128         ['add_46[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 70, 64)       4160        ['layer_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 70, 64)       0           ['dense_47[0][0]']               \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 70, 64)       4160        ['dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 70, 64)       0           ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 70, 64)       0           ['dropout_45[0][0]',             \n",
      "                                                                  'add_46[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_47 (LayerN  (None, 70, 64)      128         ['add_47[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_23 (Multi  (None, 70, 64)      24896       ['layer_normalization_47[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_47[0][0]', \n",
      "                                                                  'layer_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " add_48 (Add)                   (None, 70, 64)       0           ['add_47[0][0]',                 \n",
      "                                                                  'multi_head_attention_23[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_48 (LayerN  (None, 70, 64)      128         ['add_48[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 70, 64)       4160        ['layer_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 70, 64)       0           ['dense_49[0][0]']               \n",
      "                                                                                                  \n",
      " dense_50 (Dense)               (None, 70, 64)       4160        ['dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 70, 64)       0           ['dense_50[0][0]']               \n",
      "                                                                                                  \n",
      " add_49 (Add)                   (None, 70, 64)       0           ['dropout_47[0][0]',             \n",
      "                                                                  'add_48[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_49 (LayerN  (None, 70, 64)      128         ['add_49[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_24 (Multi  (None, 70, 64)      24896       ['layer_normalization_49[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_49[0][0]', \n",
      "                                                                  'layer_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " add_50 (Add)                   (None, 70, 64)       0           ['add_49[0][0]',                 \n",
      "                                                                  'multi_head_attention_24[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_50 (LayerN  (None, 70, 64)      128         ['add_50[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_51 (Dense)               (None, 70, 64)       4160        ['layer_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 70, 64)       0           ['dense_51[0][0]']               \n",
      "                                                                                                  \n",
      " dense_52 (Dense)               (None, 70, 64)       4160        ['dropout_48[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 70, 64)       0           ['dense_52[0][0]']               \n",
      "                                                                                                  \n",
      " add_51 (Add)                   (None, 70, 64)       0           ['dropout_49[0][0]',             \n",
      "                                                                  'add_50[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_51 (LayerN  (None, 70, 64)      128         ['add_51[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_25 (Multi  (None, 70, 64)      24896       ['layer_normalization_51[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_51[0][0]', \n",
      "                                                                  'layer_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " add_52 (Add)                   (None, 70, 64)       0           ['add_51[0][0]',                 \n",
      "                                                                  'multi_head_attention_25[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_52 (LayerN  (None, 70, 64)      128         ['add_52[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 70, 64)       4160        ['layer_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 70, 64)       0           ['dense_53[0][0]']               \n",
      "                                                                                                  \n",
      " dense_54 (Dense)               (None, 70, 64)       4160        ['dropout_50[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)           (None, 70, 64)       0           ['dense_54[0][0]']               \n",
      "                                                                                                  \n",
      " add_53 (Add)                   (None, 70, 64)       0           ['dropout_51[0][0]',             \n",
      "                                                                  'add_52[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_53 (LayerN  (None, 70, 64)      128         ['add_53[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_26 (Multi  (None, 70, 64)      24896       ['layer_normalization_53[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_53[0][0]', \n",
      "                                                                  'layer_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " add_54 (Add)                   (None, 70, 64)       0           ['add_53[0][0]',                 \n",
      "                                                                  'multi_head_attention_26[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_54 (LayerN  (None, 70, 64)      128         ['add_54[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_55 (Dense)               (None, 70, 64)       4160        ['layer_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)           (None, 70, 64)       0           ['dense_55[0][0]']               \n",
      "                                                                                                  \n",
      " dense_56 (Dense)               (None, 70, 64)       4160        ['dropout_52[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 70, 64)       0           ['dense_56[0][0]']               \n",
      "                                                                                                  \n",
      " add_55 (Add)                   (None, 70, 64)       0           ['dropout_53[0][0]',             \n",
      "                                                                  'add_54[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_55 (LayerN  (None, 70, 64)      128         ['add_55[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_27 (Multi  (None, 70, 64)      24896       ['layer_normalization_55[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_55[0][0]', \n",
      "                                                                  'layer_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " add_56 (Add)                   (None, 70, 64)       0           ['add_55[0][0]',                 \n",
      "                                                                  'multi_head_attention_27[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_56 (LayerN  (None, 70, 64)      128         ['add_56[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_57 (Dense)               (None, 70, 64)       4160        ['layer_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_54 (Dropout)           (None, 70, 64)       0           ['dense_57[0][0]']               \n",
      "                                                                                                  \n",
      " dense_58 (Dense)               (None, 70, 64)       4160        ['dropout_54[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_55 (Dropout)           (None, 70, 64)       0           ['dense_58[0][0]']               \n",
      "                                                                                                  \n",
      " add_57 (Add)                   (None, 70, 64)       0           ['dropout_55[0][0]',             \n",
      "                                                                  'add_56[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 64)          0           ['add_57[0][0]']                 \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " layer_normalization_57 (LayerN  (None, 64)          128         ['tf.__operators__.getitem_1[0][0\n",
      " ormalization)                                                   ]']                              \n",
      "                                                                                                  \n",
      " dense_59 (Dense)               (None, 7)            455         ['layer_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 541,191\n",
      "Trainable params: 541,191\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "size = 69\n",
    "block_size = 8\n",
    "hidden_dim = 64\n",
    "num_layers = 16\n",
    "num_heads = 4\n",
    "key_dim = (\n",
    "    hidden_dim // num_heads\n",
    ")  # usually good practice for key_dim to be hidden_dim//num_heads...this is why we do Multi-Head attention\n",
    "value_dim = key_dim * 2\n",
    "mlp_dim = hidden_dim\n",
    "dropout_rate = 0.05\n",
    "num_classes = 7\n",
    "\n",
    "\n",
    "trans = build_ViT(\n",
    "    size,\n",
    "    block_size,\n",
    "    hidden_dim,\n",
    "    num_layers,\n",
    "    num_heads,\n",
    "    key_dim,\n",
    "    value_dim,\n",
    "    mlp_dim,\n",
    "    dropout_rate,\n",
    "    num_classes,\n",
    ")\n",
    "trans.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24896"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    ((hidden_dim * key_dim + key_dim) * 2 + hidden_dim * value_dim + value_dim)\n",
    "    * num_heads\n",
    "    + (value_dim * num_heads) * hidden_dim\n",
    "    + hidden_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect4_testing = connect4_wflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (732538, 6, 7, 2), Validation set: (156973, 6, 7, 2), Test set: (156973, 6, 7, 2)\n"
     ]
    }
   ],
   "source": [
    "# Extract features (board states) and labels (recommended moves)\n",
    "X = np.stack(\n",
    "    connect4_testing[\"Board State\"].values\n",
    ")  # Convert board states into a NumPy array\n",
    "y = connect4_testing[\"Move\"].values\n",
    "\n",
    "# Normalize the board states (optional for CNNs)\n",
    "X = X.astype(\"float32\") / 1.0  # Assuming board states are binary (0 or 1)\n",
    "\n",
    "# Convert labels to one-hot encoding (required for multi-class classification)\n",
    "num_classes = 7  # Moves are in columns 0-6\n",
    "y = to_categorical(y, num_classes)\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Training set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\"\n",
    ")\n",
    "\n",
    "\n",
    "ndata_train = X_train.shape[0]\n",
    "ndata_test = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(y_train, axis=1)  # Convert from one-hot to class indices\n",
    "y_test = np.argmax(y_test, axis=1)  # Convert from one-hot to class indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_test = np.zeros((1, 6, 7, 2), dtype=int)  # Only one board (ndata_train=1), 6x7 size, 2 players\n",
    "\n",
    "# Fill the board with increasing numbers for players\n",
    "X_train_test[0, :, :, 0] = np.arange(1, 7).reshape(6, 1) * np.ones((1, 7))  # Player 1: Increase across rows\n",
    "X_train_test[0, :, :, 1] = np.arange(1, 8).reshape(1, 7)  # Player 2: Increase across columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732538, 69, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize example board size\n",
    "n, m = 6, 7  # Rows and columns for Connect Four\n",
    "block_size = 8  # Length of a winning combination (4-in-a-row)\n",
    "\n",
    "# Initialize x_train_ravel with the correct shape\n",
    "ndata_train = X_train.shape[0]\n",
    "x_train_ravel = np.zeros((ndata_train, 69, block_size))  # 69 possible 4-in-a-row combinations per board, each flattened to length 4\n",
    "\n",
    "# Function to extract all winning combinations from the board\n",
    "def extract_combinations(board):\n",
    "    combinations = []\n",
    "    \n",
    "    # Horizontal combinations\n",
    "    for row in range(n):\n",
    "        for col in range(m - 3):  # can extract 4 combinations horizontally\n",
    "            combinations.append(board[row, col:col + 4])\n",
    "\n",
    "    # Vertical combinations\n",
    "    for col in range(m):\n",
    "        for row in range(n - 3):  # can extract 4 combinations vertically\n",
    "            combinations.append(board[row:row + 4, col])\n",
    "    \n",
    "    # Diagonal combinations (top-left to bottom-right)\n",
    "    for row in range(n - 3):\n",
    "        for col in range(m - 3):  # can extract 4 combinations diagonally (top-left to bottom-right)\n",
    "            combinations.append([board[row + i, col + i] for i in range(4)])\n",
    "\n",
    "    # Diagonal combinations (top-right to bottom-left)\n",
    "    for row in range(n - 3):\n",
    "        for col in range(3, m):  # can extract 4 combinations diagonally (top-right to bottom-left)\n",
    "            combinations.append([board[row + i, col - i] for i in range(4)])\n",
    "    \n",
    "    return combinations\n",
    "\n",
    "# Process each image/board and extract all winning combinations\n",
    "for img in range(ndata_train):\n",
    "    # Extract the board data for both players (using both channels)\n",
    "    player1_board = X_train[img, :, :, 0]  # Board data for player 1\n",
    "    player2_board = X_train[img, :, :, 1]  # Board data for player 2\n",
    "    \n",
    "    # Extract all winning combinations for player 1 and player 2\n",
    "    combinations_player1 = extract_combinations(player1_board)\n",
    "    combinations_player2 = extract_combinations(player2_board)\n",
    "    \n",
    "    # Combine player 1 and player 2 information into a single 8-length vector (4 positions x 2 players)\n",
    "    for ind in range(69):  # 69 possible combinations\n",
    "        combined_combination = []\n",
    "        for i in range(4):  # 4 positions in the combination\n",
    "            combined_combination.append(combinations_player1[ind][i])  # Player 1\n",
    "            combined_combination.append(combinations_player2[ind][i])  # Player 2\n",
    "        \n",
    "        # Flatten and store in x_train_ravel\n",
    "        x_train_ravel[img, ind, :] = np.array(combined_combination).ravel()\n",
    "\n",
    "# Now x_train_ravel has the shape (ndata_train, 69, 4) as requested\n",
    "x_train_ravel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156973, 69, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize example board size\n",
    "n, m = 6, 7  # Rows and columns for Connect Four\n",
    "block_size = 8  # Length of a winning combination (4-in-a-row)\n",
    "\n",
    "# Initialize x_train_ravel with the correct shape\n",
    "ndata_test = X_test.shape[0]\n",
    "x_test_ravel = np.zeros((ndata_test, 69, block_size))  # 69 possible 4-in-a-row combinations per board, each flattened to length 4\n",
    "\n",
    "# Function to extract all winning combinations from the board\n",
    "def extract_combinations(board):\n",
    "    combinations = []\n",
    "    \n",
    "    # Horizontal combinations\n",
    "    for row in range(n):\n",
    "        for col in range(m - 3):  # can extract 4 combinations horizontally\n",
    "            combinations.append(board[row, col:col + 4])\n",
    "\n",
    "    # Vertical combinations\n",
    "    for col in range(m):\n",
    "        for row in range(n - 3):  # can extract 4 combinations vertically\n",
    "            combinations.append(board[row:row + 4, col])\n",
    "    \n",
    "    # Diagonal combinations (top-left to bottom-right)\n",
    "    for row in range(n - 3):\n",
    "        for col in range(m - 3):  # can extract 4 combinations diagonally (top-left to bottom-right)\n",
    "            combinations.append([board[row + i, col + i] for i in range(4)])\n",
    "\n",
    "    # Diagonal combinations (top-right to bottom-left)\n",
    "    for row in range(n - 3):\n",
    "        for col in range(3, m):  # can extract 4 combinations diagonally (top-right to bottom-left)\n",
    "            combinations.append([board[row + i, col - i] for i in range(4)])\n",
    "    \n",
    "    return combinations\n",
    "\n",
    "# Process each image/board and extract all winning combinations\n",
    "for img in range(ndata_test):\n",
    "    # Extract the board data for both players (using both channels)\n",
    "    player1_board = X_test[img, :, :, 0]  # Board data for player 1\n",
    "    player2_board = X_test[img, :, :, 1]  # Board data for player 2\n",
    "    \n",
    "    # Extract all winning combinations for player 1 and player 2\n",
    "    combinations_player1 = extract_combinations(player1_board)\n",
    "    combinations_player2 = extract_combinations(player2_board)\n",
    "    \n",
    "    # Combine player 1 and player 2 information into a single 8-length vector (4 positions x 2 players)\n",
    "    for ind in range(69):  # 69 possible combinations\n",
    "        combined_combination = []\n",
    "        for i in range(4):  # 4 positions in the combination\n",
    "            combined_combination.append(combinations_player1[ind][i])  # Player 1\n",
    "            combined_combination.append(combinations_player2[ind][i])  # Player 2\n",
    "        \n",
    "        # Flatten and store in x_train_ravel\n",
    "        x_test_ravel[img, ind, :] = np.array(combined_combination).ravel()\n",
    "\n",
    "# Now x_train_ravel has the shape (ndata_train, 69, 4) as requested\n",
    "x_test_ravel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board State Shape: (605018, 6, 7, 2)\n",
      "Move Labels Shape: (605018,)\n",
      "Training Shape: (484014, 6, 7, 2) (484014, 7)\n",
      "Test Shape: (121004, 6, 7, 2) (121004, 7)\n"
     ]
    }
   ],
   "source": [
    "# # Extract board states and moves\n",
    "# X = np.array(connect4_wflip[\"Board State\"].tolist())  # Convert to NumPy array\n",
    "# y = np.array(connect4_wflip[\"Move\"])  # Target moves (0 to 6)\n",
    "\n",
    "# # Verify shapes\n",
    "# print(\"Board State Shape:\", X.shape)  # Expecting (num_samples, 6, 7, 2)\n",
    "# print(\"Move Labels Shape:\", y.shape)  # Expecting (num_samples,)\n",
    "\n",
    "# # Convert moves to one-hot encoding (since we have 7 possible moves)\n",
    "# y_onehot = tf.keras.utils.to_categorical(y, num_classes=7)\n",
    "\n",
    "# # Split into train/test sets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y_onehot, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# print(\"Training Shape:\", X_train.shape, y_train.shape)\n",
    "# print(\"Test Shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "15567/15567 [==============================] - 6497s 417ms/step - loss: 1.4028 - accuracy: 0.4460 - val_loss: 1.2753 - val_accuracy: 0.5014\n",
      "Epoch 2/4\n",
      "15567/15567 [==============================] - 6828s 439ms/step - loss: 1.2395 - accuracy: 0.5147 - val_loss: 1.1932 - val_accuracy: 0.5377\n",
      "Epoch 3/4\n",
      "15567/15567 [==============================] - 5838s 375ms/step - loss: 1.1808 - accuracy: 0.5395 - val_loss: 1.1551 - val_accuracy: 0.5525\n",
      "Epoch 4/4\n",
      "15567/15567 [==============================] - 5577s 358ms/step - loss: 1.1422 - accuracy: 0.5554 - val_loss: 1.1357 - val_accuracy: 0.5597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3491793d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.fit(x_train_ravel, y_train, epochs=4, batch_size=40, validation_split=0.15) # Dans\n",
    "# history = transformer.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     epochs=1,  # Increase for better performance\n",
    "#     batch_size=32,\n",
    "# )  # Not Dans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4906/4906 [==============================] - 591s 120ms/step - loss: 1.1361 - accuracy: 0.5577\n"
     ]
    }
   ],
   "source": [
    "out = trans.evaluate(x_test_ravel, y_test) # Dans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5576946139335632"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1] # Dans\n",
    "\n",
    "# Evaluate on test set\n",
    "# test_loss, test_acc = transformer.evaluate(X_test, y_test)\n",
    "# print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans.save(\"connect4_transformer.h5\") Dans\n",
    "trans.save(\"transformer_carson_attempt1.keras\") \n",
    "\n",
    "# Save the trained model\n",
    "# transformer.save(\"connect4_transformer_test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
